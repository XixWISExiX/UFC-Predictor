{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1911389/4036690796.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import PreProcessData as pre\n",
    "import imp\n",
    "imp.reload(pre)\n",
    "X_train, X_valid, y_train, y_valid = pre.PreProcessData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "        self.biases_input_hidden = np.zeros((1, hidden_size))\n",
    "        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "        self.biases_hidden_output = np.zeros((1, output_size))\n",
    "\n",
    "    # TODO NEED Softmax function\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        # Input to hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights_input_hidden) + self.biases_input_hidden\n",
    "        self.hidden_activation = self.sigmoid(self.hidden_sum)\n",
    "\n",
    "        # Hidden to output layer\n",
    "        self.output_sum = np.dot(self.hidden_activation, self.weights_hidden_output) + self.biases_hidden_output\n",
    "        self.output_activation = self.sigmoid(self.output_sum)\n",
    "\n",
    "        return self.output_activation\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        # Output layer\n",
    "        error_output = y - output\n",
    "        delta_output = error_output * self.sigmoid_derivative(output)\n",
    "\n",
    "        # Hidden layer\n",
    "        # error_hidden = delta_output.dot(self.weights_hidden_output.T)\n",
    "        error_hidden = error_output.dot(self.weights_hidden_output.T)\n",
    "        # error_hidden = error_output.dot(self.hidden_activation.T)\n",
    "        # TODO Make the matricies match each other\n",
    "        # delta_hidden = error_hidden * self.sigmoid_derivative(self.hidden_activation.dot(self.weights_hidden_output))\n",
    "        delta_hidden = error_hidden * self.sigmoid_derivative(self.hidden_activation)\n",
    "        # print(self.hidden_activation.T.shape)\n",
    "        # print(delta_output.shape)\n",
    "        # print(delta_hidden.shape)\n",
    "        # print(error_hidden.shape)\n",
    "\n",
    "        # Update weights and biases\n",
    "        # self.weights_hidden_output += self.hidden_activation.T.dot(delta_output) * self.learning_rate\n",
    "        self.weights_hidden_output += self.hidden_activation.T.dot(error_output) * self.learning_rate\n",
    "        self.biases_hidden_output += np.sum(error_output, axis=0, keepdims=True) * self.learning_rate\n",
    "        self.weights_input_hidden += X.T.dot(delta_hidden) * self.learning_rate\n",
    "        self.biases_input_hidden += np.sum(delta_hidden, axis=0, keepdims=True) * self.learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs):\n",
    "        y = y.reshape(-1,1)\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            output = self.feedforward(X)\n",
    "\n",
    "            # Backpropagation\n",
    "            self.backward(X, y, output)\n",
    "\n",
    "            # Print loss every 100 epochs\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                loss = np.mean(np.square(y - output))\n",
    "                print(f'Epoch {epoch + 1}, Loss: {loss:.4f}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.feedforward(X)\n",
    "\n",
    "    def validate(self, y_pred, y_valid):\n",
    "        num_of_correct_predictions = np.sum((y_pred >= 0.5) == y_valid)\n",
    "        accuracy = num_of_correct_predictions / len(y_valid)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.2462\n",
      "Epoch 200, Loss: 0.2396\n",
      "Epoch 300, Loss: 0.2354\n",
      "Epoch 400, Loss: 0.2314\n",
      "Epoch 500, Loss: 0.2291\n",
      "Epoch 600, Loss: 0.2280\n",
      "Epoch 700, Loss: 0.2269\n",
      "Epoch 800, Loss: 0.2360\n",
      "Epoch 900, Loss: 0.2326\n",
      "Epoch 1000, Loss: 0.2333\n",
      "Epoch 1100, Loss: 0.2269\n",
      "Epoch 1200, Loss: 0.2222\n",
      "Epoch 1300, Loss: 0.2242\n",
      "Epoch 1400, Loss: 0.2110\n",
      "Epoch 1500, Loss: 0.2214\n",
      "Epoch 1600, Loss: 0.2263\n",
      "Epoch 1700, Loss: 0.2006\n",
      "Epoch 1800, Loss: 0.2085\n",
      "Epoch 1900, Loss: 0.2078\n",
      "Epoch 2000, Loss: 0.2081\n",
      "Epoch 2100, Loss: 0.2039\n",
      "Epoch 2200, Loss: 0.2165\n",
      "Epoch 2300, Loss: 0.2153\n",
      "Epoch 2400, Loss: 0.2302\n",
      "Epoch 2500, Loss: 0.1929\n",
      "Epoch 2600, Loss: 0.1743\n",
      "Epoch 2700, Loss: 0.2404\n",
      "Epoch 2800, Loss: 0.1613\n",
      "Epoch 2900, Loss: 0.2216\n",
      "Epoch 3000, Loss: 0.1627\n",
      "Epoch 3100, Loss: 0.2138\n",
      "Epoch 3200, Loss: 0.3052\n",
      "Epoch 3300, Loss: 0.2530\n",
      "Epoch 3400, Loss: 0.1540\n",
      "Epoch 3500, Loss: 0.1546\n",
      "Epoch 3600, Loss: 0.1576\n",
      "Epoch 3700, Loss: 0.1629\n",
      "Epoch 3800, Loss: 0.1510\n",
      "Epoch 3900, Loss: 0.2124\n",
      "Epoch 4000, Loss: 0.1618\n",
      "Epoch 4100, Loss: 0.1555\n",
      "Epoch 4200, Loss: 0.1446\n",
      "Epoch 4300, Loss: 0.1721\n",
      "Epoch 4400, Loss: 0.1435\n",
      "Epoch 4500, Loss: 0.1803\n",
      "Epoch 4600, Loss: 0.1451\n",
      "Epoch 4700, Loss: 0.1393\n",
      "Epoch 4800, Loss: 0.1559\n",
      "Epoch 4900, Loss: 0.1409\n",
      "Epoch 5000, Loss: 0.1366\n",
      "Epoch 5100, Loss: 0.1344\n",
      "Epoch 5200, Loss: 0.1803\n",
      "Epoch 5300, Loss: 0.1507\n",
      "Epoch 5400, Loss: 0.1431\n",
      "Epoch 5500, Loss: 0.1576\n",
      "Epoch 5600, Loss: 0.2161\n",
      "Epoch 5700, Loss: 0.1845\n",
      "Epoch 5800, Loss: 0.1786\n",
      "Epoch 5900, Loss: 0.1712\n",
      "Epoch 6000, Loss: 0.1877\n",
      "Epoch 6100, Loss: 0.1740\n",
      "Epoch 6200, Loss: 0.1694\n",
      "Epoch 6300, Loss: 0.1679\n",
      "Epoch 6400, Loss: 0.1624\n",
      "Epoch 6500, Loss: 0.1595\n",
      "Epoch 6600, Loss: 0.3417\n",
      "Epoch 6700, Loss: 0.1711\n",
      "Epoch 6800, Loss: 0.1649\n",
      "Epoch 6900, Loss: 0.1627\n",
      "Epoch 7000, Loss: 0.1596\n"
     ]
    }
   ],
   "source": [
    "# Create and train the neural network\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 4 # Number of neurons in the hidden layer\n",
    "# output_size = X_train.shape[0]\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "epochs = 7000\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size, learning_rate)\n",
    "model.train(np.array(X_train), np.array(y_train), epochs)\n",
    "predictions = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6655473472128945\n",
      "0.2961719274680994\n",
      "[[5.66720631e-87]\n",
      " [1.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [6.96493173e-01]\n",
      " [1.04633169e-82]\n",
      " [5.50057997e-01]\n",
      " [1.00000000e+00]\n",
      " [5.48183661e-01]\n",
      " [1.00000000e+00]\n",
      " [4.63580159e-01]]\n",
      "[0 1 1 0 1 0 0 0 1 1]\n",
      "(1489, 1)\n",
      "(1489,)\n"
     ]
    }
   ],
   "source": [
    "def validate(y_pred, y_valid):\n",
    "    num_of_correct_predictions = np.sum((y_pred >= 0.5) == y_valid)\n",
    "    accuracy = num_of_correct_predictions / len(y_valid)\n",
    "    return accuracy\n",
    "\n",
    "y_valid_np = np.array(y_valid)\n",
    "y_valid_np = y_valid_np.reshape(-1,1)\n",
    "print(validate(np.array(predictions), y_valid_np))\n",
    "print(model.validate(np.array(predictions), y_valid_np))\n",
    "\n",
    "print(np.array(predictions)[10:20])\n",
    "print(np.array(y_valid)[10:20])\n",
    "\n",
    "print((np.array(predictions)).shape)\n",
    "print((np.array(y_valid)).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
